{
 "metadata": {
  "name": "",
  "signature": "sha256:00f2b45ea9dc7d8506263d9c1f8860e90295a47b212552aaebacfc0284489151"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%javascript\n",
      "function is_local(){\n",
      "  return (document.location.hostname == \"localhost\" || document.location.hostname == '127.0.0.1')\n",
      "}\n",
      "var url = is_local() ? \"http://localhost:8000/theme/custom.js\" : \"http://odhk.github.io/hyrule_theme/custom.js\"\n",
      "$.getScript(url)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "javascript": [
        "function is_local(){\n",
        "  return (document.location.hostname == \"localhost\" || document.location.hostname == '127.0.0.1')\n",
        "}\n",
        "var url = is_local() ? \"http://localhost:8000/theme/custom.js\" : \"http://odhk.github.io/hyrule_theme/custom.js\"\n",
        "$.getScript(url)"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Javascript at 0x7fb5941499d0>"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Big Data: AWS & StarCluster"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> Not everything that can be counted counts, and not everything that counts can be counted.\n",
      "\n",
      "<footer>~ William Bruce Cameron</footer>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![break](assets/agenda.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Objectives**\n",
      "\n",
      "1. Define Big Data\n",
      "2. Differentiate the various Amazon Web Services\n",
      "3. Spin up a Cluster with StarCluster\n",
      "\n",
      "\n",
      "**Labs**\n",
      "1. WikiPedia Dataset Analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![break](assets/theory.png)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Big Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What does \u201cbig data\u201d actually refer to? A common approach is to talk about _Big data_ in terms of the 3 V's commonly associated with it."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "-   Volume\n",
      "-   Velocity\n",
      "-   Variety"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "The 3 Vs of Big Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Volume (i.e. more than can fit in memory on your laptop)  \n",
      "    - e.g. Amazon\u2019s user behavior data\n",
      "\n",
      "\n",
      "- Velocity (i.e. faster than standard machines can process)\n",
      "    - e.g. Twitter\u2019s \u201cFirehose\u201d of tweets\n",
      "\n",
      "\n",
      "- Variety (i.e. does not conform to a single structure)\n",
      "    - e.g. Google\u2019s cache of web pages"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this course, we will not deal with velocity. That is really more of an engineering problem than a data science problem. In fact, all three of these are engineering problems, but only the first and the third are really germane to Data Science. That said, as a Data Scientist, it is probably only a matter of time before someone asks you to create a real-time dashboard. Such a thing, while cool, is often very difficult to create and has questionable utility for anyone besides an operations engineer or a day trader, and they already have real-time dashboards."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Meeting the needs of Big Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How would you approach dealing with this kind of data? One approach would be to get a huge supercomputer. But this has some obvious drawbacks: "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- expensive\n",
      "- difficult to maintain\n",
      "- scalability is bounded"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Instead of one huge machine, what if we got a bunch of regular (*commodity*) machines? This has obvious benefits!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- cheaper\n",
      "- easier to maintain\n",
      "- scalability is unbounded (just add more nodes to the *cluster*)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can visualize this *horizontal* cluster architecture as a single client-multiple server relationship:  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![](assets/scoverview.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are two ways to process data in a distributed architecture:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. move data to code (& processing power)\n",
      "    - SETI\n",
      "2. move code to data\n",
      "    - map-reduce -> less overhead (network traffic, disk I/O)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> \u201cComputing nodes are the same as storage nodes.\u201d"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Divide and conquer is a fundamental algorithmic technique for solving a given task, whose steps include:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. split task into subtasks\n",
      "1. solve these subtasks independently\n",
      "1. recombine the subtask results into a final result"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One famous example of divide and conquer is *merge sort*."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![](assets/Merge_sort_algorithm_diagram.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The defining characteristic of a problem that is suitable for the divide and conquer approach is that it can be broken down into independent subtasks."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tasks that can be parallelized in this way include:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* count, sum, average\n",
      "* grep, sort, inverted index\n",
      "* graph traversals, some ML algorithms"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What if you can't afford a cluster?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Amazon Web Services"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![](assets/AWS-Overview-of-Services.jpg)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- IAM: Identity and Access Management\n",
      "- S3: Simple Storage Service\n",
      "- EC2: Elastic Cloud Compute\n",
      "- EMR: Elastic MapReduce"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Regions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* us-east-1 (North Virginia)\n",
      "* us-west-1 (Northern California)\n",
      "* ap-southeast-1 (Singapore)\n",
      "* eu-west-1 (Ireland)\n",
      "* also other regions in Asia, Europe, North and South America"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Availability Zones (AZ)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Each region has several availability zones.\n",
      "\n",
      "AZs should rarely matter, but important to know what it is (and not confuse AZs with regions). AZ will rarely matter. Region often will."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Types of authentication"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> Warning: the word *key* is used a lot to mean different things.)\n",
      " \n",
      "1. Key & Secret\n",
      "    - Key = 20 character long token (all upper-case)\n",
      "    - Secret = 40 character long string\n",
      "    - Used for all AWS\n",
      "    - Created and managed in IAM\n",
      "    - Not region specific\n",
      "2. Keypair\n",
      "    - RSA encrypted\n",
      "    - Used specifically for SSH into EC2 (including EMR)\n",
      "    - Region specific\n",
      "    - Created and managed in EC2\n",
      "3. Other forms of authentication\n",
      "    - Alternative to Key & Secret\n",
      "    - Managed in IAM\n",
      "    - Useful for granting others partial access to your AWS resources  \n",
      "        (i.e. giving a friend write access to a specific S3 bucket)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "S3 (Simple Storage Service)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Sort of a file system\n",
      "    - Buckets ~ Folders\n",
      "    - Keys ~ Files (Note: a different meaning for the word *key* in this context)\n",
      "    - Subdirectories aren't really folders, but rather just prefixes to the key name\n",
      "- Region Specific\n",
      "    - but it usually doesn't matter (except for latency)\n",
      "- Relatively Cheap\n",
      "- Complex Permission Structure (about as complex as a real file system)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "EC2 (Elastic Cloud Compute)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Instance Types"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Optimization\n",
      "    - Compute Optimized\n",
      "    - Memory Optimized\n",
      "    - Storage Optimized\n",
      "    - General Purpose\n",
      "    \n",
      "    \n",
      "- Pricing Examples:\n",
      "    - t1.micro\n",
      "        - 1 CPU\n",
      "        - 615 MB RAM\n",
      "        - \\$0.02 per Hour\n",
      "    - i2.8xlarge\n",
      "        - 32 CPUs\n",
      "        - 244 GB RAM\n",
      "        - \\$6.82 per Hour\n",
      "    - m3.xlarge \n",
      "        - 4 CPUs\n",
      "        - 15 GB RAM\n",
      "        - \\$0.28 per Hour\n",
      "        \n",
      "- Not all instance types available in all regions (e.g. High Storage Instances not available in us-west-1)\n",
      "- Prices may vary (e.g. instances in us-west-1 are often more expensive)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "AMI (Amazon Machine Images)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* A machine image is a copyable snapshot of an instance's contents and configuration\n",
      "* If you've ever run a virtual machine (e.g. VirtualBox, VMware, Parallels), you may be familiar\n",
      "* EC2 instances start as AMIs that are then *instantiated*\n",
      "* StarCluster uses AMIs extensively to preconfigure EC2 instances to create a cluster\n",
      "* A well-configured AMI can save a lot of time\n",
      "* AMIs are region specific. Copies to other regions receive new ID\n",
      "\n",
      "A well-configured AMI can save a lot of time because you don't have to install software on every instance after it's booted up (the software is effectively pre-installed).\n",
      "They can be copied, but only by the creator and it will get a new ID when that happens."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "EMR (Elastic MapReduce)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Hadoop in the Cloud "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Uses EC2 instances\n",
      "* Web interface for provisioning cluster\n",
      "* Installs Hadoop, etc. automatically\n",
      "* Installs Hive, Pig, HBase automatically if desired\n",
      "* Provides a web interface to running Hadoop Streaming jobs.\n",
      "* Charges a small premium on top of EC2 prices"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One thing EMR does that StarCluster doesn't is it automatically configures Hadoop to be able to read your S3 buckets as if they were part of HDFS. This has to be done manually in StarCluster (or any other software that runs Hadoop on EC2 (e.g. Whirr, etc.))"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "StarCluster"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![](assets/scoverview.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "StarCluster comes out of the STAR program at MIT. STAR stands for \"Software Tools for Academics and Researchers\". It is used to quickly provision a cluster of EC2 instances. Like EMR, it automatically configures them to be used as a cluster (rather than as independent machines) with one controller and many workers. Unlike EMR, it does not have a GUI. Also, Hadoop is just one of many plugins for StarCluster. The most important plugin, however, is IPython Cluster."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![break](assets/code.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "------------------------------------------\n",
      "Wikipedia XML Data\n",
      "------------------------------------------\n",
      "A complete copy of all Wikimedia wikis, in the form of wikitext source and metadata embedded in XML.\n",
      "<table>\n",
      "          <tr>\n",
      "            <td class=\"metaLeft\">\n",
      "              Size:\n",
      "            </td>\n",
      "            <td class=\"metaRight\">\n",
      "              \n",
      "500GB</td>\n",
      "          </tr>\n",
      "          <tr>\n",
      "            <td class=\"metaLeft\">\n",
      "              Source:\n",
      "            </td>\n",
      "            <td class=\"metaRight\">\n",
      "              \n",
      "Wikimedia Foundation (http://download.wikipedia.org/backup-index.html)</td>\n",
      "          </tr>\n",
      "          <tr>\n",
      "            <td class=\"metaLeft\">\n",
      "              Created On: \n",
      "            </td>\n",
      "            <td class=\"metaRight\">\n",
      "              \n",
      "<span class=\"timestamp\">May 15, 2009 12:09 AM GMT</span>\n",
      " \n",
      "            </td>\n",
      "          </tr>\n",
      "          <tr>\n",
      "            <td class=\"metaLeft\">\n",
      "              Last Updated:\n",
      "            </td>\n",
      "            <td class=\"metaRight\">\n",
      "              \n",
      "<span class=\"timestamp\">September 29, 2009  1:09 AM GMT</span>\n",
      " \n",
      "            </td>\n",
      "          </tr>\n",
      "        </table>  \n",
      "        \n",
      "http://aws.amazon.com/datasets/Encyclopedic/2506"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Part I : Preliminary investigation of our dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First we need to install some modules that will allow us to interface with AWS."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!pip install boto"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ensure that boto succesfully installed\n",
      "import boto"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Instructions: http://star.mit.edu/cluster/docs/latest/installation.html\n",
      "!pip install starcluster"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Check whether starcluster was succesfully added. If conda doesn't pick \n",
      "# up on the installs pip makes, you'll need to add the site-packages directory \n",
      "# from your default python install\n",
      "import starcluster as sc\n",
      "sc.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named starcluster",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-5-12723cfa415c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# up on the installs pip makes, you'll need to add the site-packages directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# from your default python install\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstarcluster\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mImportError\u001b[0m: No module named starcluster"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ask python where it installs its site packages\n",
      "!/usr/bin/env python -c \"import site; print site.getsitepackages()\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['/usr/lib64/python2.7/site-packages', '/usr/lib/python2.7/site-packages', '/usr/lib/site-python']\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# So, in this example, this is where my site-packages are located. You can add\n",
      "# Them with sys.path.append\n",
      "import sys\n",
      "sys.path.append(\"/usr/lib/python2.7/site-packages/\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sanity check to make sure it was added correctly.\n",
      "sys.path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "['',\n",
        " '/home/io/ga/ds/DS_HK_3/notebooks',\n",
        " '/home/io/Code',\n",
        " '/home/io/.tools/anaconda/lib/python27.zip',\n",
        " '/home/io/.tools/anaconda/lib/python2.7',\n",
        " '/home/io/.tools/anaconda/lib/python2.7/plat-linux2',\n",
        " '/home/io/.tools/anaconda/lib/python2.7/lib-tk',\n",
        " '/home/io/.tools/anaconda/lib/python2.7/lib-old',\n",
        " '/home/io/.tools/anaconda/lib/python2.7/lib-dynload',\n",
        " '/home/io/.tools/anaconda/lib/python2.7/site-packages',\n",
        " '/home/io/.tools/anaconda/lib/python2.7/site-packages/PIL',\n",
        " '/home/io/.tools/anaconda/lib/python2.7/site-packages/Sphinx-1.2.3-py2.7.egg',\n",
        " '/home/io/.tools/anaconda/lib/python2.7/site-packages/runipy-0.1.1-py2.7.egg',\n",
        " '/home/io/.tools/anaconda/lib/python2.7/site-packages/setuptools-5.8-py2.7.egg',\n",
        " '/home/io/.tools/anaconda/lib/python2.7/site-packages/IPython/extensions',\n",
        " '/usr/lib/python2.7/site-packages/']"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import StarCluster as you normally would\n",
      "import starcluster as sc\n",
      "sc.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "'0.95.5'"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "from boto.s3.connection import S3Connection\n",
      "from IPython.parallel import Client"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once you have all your modules setup, you'll want to gain the ability to authenticate with AWS. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![](assets/aws-security-1.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then select `Access Keys (Access Key ID and Secret Access Key)` and _make sure_ to download your rootkey.csv to your home directory. \n",
      "You can navigate there by typing 'cd ~` into your terminal."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![](assets/aws-security-2.png)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Once your rootkey is downloaded into your `~/`, you can now connect with it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(os.path.expanduser('~/rootkey.csv')) as f:\n",
      "    credentials = f.read().splitlines()\n",
      "    key, secret = credentials[0].split('=')[1], credentials[1].split('=')[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s3conn = S3Connection(key, secret)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datasets = s3conn.get_bucket('datasets.elasticmapreduce', validate=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wikipediaxml_keys = datasets.get_all_keys(prefix='wikipediaxml')\n",
      "len(wikipediaxml_keys)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "117"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Get the smallest data subset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[k.size for k in wikipediaxml_keys].index(\n",
      "    min(k.size for k in wikipediaxml_keys))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "60"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# N.B. This takes a few minutes...\n",
      "data = wikipediaxml_keys[60].get_contents_as_string()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data[:1000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "'<page>    <title>Martynas Gostautas</title>    <id>16446159</id>    <redirect />    <revision>      <id>199730842</id>      <timestamp>2008-03-21T01:27:01Z</timestamp>      <contributor>        <username>Eubot</username>        <id>231599</id>      </contributor>      <comment>Redirected page to [[Martynas Go??tautas]].</comment>      <text xml:space=\"preserve\">#REDIRECT [[Martynas Go??tautas]] {{R from title without diacritics}}</text>    </revision></page>\\r<page>    <title>Yolanda Ivonne Montez Farrington</title>    <id>16446163</id>    <redirect />    <revision>      <id>199730870</id>      <timestamp>2008-03-21T01:27:09Z</timestamp>      <contributor>        <username>Eubot</username>        <id>231599</id>      </contributor>      <comment>Redirected page to [[Yolanda &quot;Tongolele&quot; Montes]]. (&quot;Yolanda Ivonne M??ntez Farrington&quot;).</comment>      <text xml:space=\"preserve\">#REDIRECT [[Yolanda &quot;Tongolele&quot; Montes]] {{R from title without diacritics}}</text>'"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's explore the XML document object model using Python's minidom module:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.split('\\r')[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "'<page>    <title>Yolanda Ivonne Montez Farrington</title>    <id>16446163</id>    <redirect />    <revision>      <id>199730870</id>      <timestamp>2008-03-21T01:27:09Z</timestamp>      <contributor>        <username>Eubot</username>        <id>231599</id>      </contributor>      <comment>Redirected page to [[Yolanda &quot;Tongolele&quot; Montes]]. (&quot;Yolanda Ivonne M??ntez Farrington&quot;).</comment>      <text xml:space=\"preserve\">#REDIRECT [[Yolanda &quot;Tongolele&quot; Montes]] {{R from title without diacritics}}</text>    </revision></page>'"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from xml.dom import minidom\n",
      "\n",
      "dom = minidom.parseString(data.split('\\r')[1])\n",
      "print dom.firstChild.toprettyxml()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<page>\n",
        "\t    \n",
        "\t<title>Yolanda Ivonne Montez Farrington</title>\n",
        "\t    \n",
        "\t<id>16446163</id>\n",
        "\t    \n",
        "\t<redirect/>\n",
        "\t    \n",
        "\t<revision>\n",
        "\t\t      \n",
        "\t\t<id>199730870</id>\n",
        "\t\t      \n",
        "\t\t<timestamp>2008-03-21T01:27:09Z</timestamp>\n",
        "\t\t      \n",
        "\t\t<contributor>\n",
        "\t\t\t        \n",
        "\t\t\t<username>Eubot</username>\n",
        "\t\t\t        \n",
        "\t\t\t<id>231599</id>\n",
        "\t\t\t      \n",
        "\t\t</contributor>\n",
        "\t\t      \n",
        "\t\t<comment>Redirected page to [[Yolanda &quot;Tongolele&quot; Montes]]. (&quot;Yolanda Ivonne M??ntez Farrington&quot;).</comment>\n",
        "\t\t      \n",
        "\t\t<text xml:space=\"preserve\">#REDIRECT [[Yolanda &quot;Tongolele&quot; Montes]] {{R from title without diacritics}}</text>\n",
        "\t\t    \n",
        "\t</revision>\n",
        "</page>\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "title = dom.firstChild.getElementsByTagName('title')[0]\n",
      "title.lastChild.wholeText"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "u'Yolanda Ivonne Montez Farrington'"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "titles1 = [title.lastChild.wholeText \n",
      "     for entry in data.split('\\r')[:-1] \n",
      "         for title in minidom.parseString(entry)\n",
      "             .firstChild.getElementsByTagName('title')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 25.6 s, sys: 0 ns, total: 25.6 s\n",
        "Wall time: 25.5 s\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titles1[:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "[u'Martynas Gostautas',\n",
        " u'Yolanda Ivonne Montez Farrington',\n",
        " u'Radhusgrand',\n",
        " u'Soren sjosten',\n",
        " u\"Allegations of Qur'an desecration at Guantanamo Bay\",\n",
        " u'Gross Quenstedt',\n",
        " u'Yesuekhei',\n",
        " u'Coat of arms of Saint-Barthelemy',\n",
        " u'Mohamed Abdelfatah',\n",
        " u'Zarkovac (Sombor)',\n",
        " u'Istedloven',\n",
        " u'Aero-Difusion D-1190S Compostela',\n",
        " u'Helene Gosselin',\n",
        " u'Arvid Jaernefelt',\n",
        " u'Wurm Ice Age',\n",
        " u'Rederi Ab Alandsfarjan',\n",
        " u'Praca',\n",
        " u'Pera rocha',\n",
        " u'Mikinai',\n",
        " u'T. Noldeke',\n",
        " u'O ro Se do Bheatha Bhaile',\n",
        " u'Michalowka, Biala Podlaska County',\n",
        " u'Orebro SK Bandy',\n",
        " u'Tonfoen',\n",
        " u'Pluederhausen',\n",
        " u'Charles Noyes Forbes',\n",
        " u'Milledgeville, GA mSA',\n",
        " u'Santa Barbara department',\n",
        " u'Happi Mande Seido',\n",
        " u'Nunchritz',\n",
        " u'IFK Norrkoping (disambiguation)',\n",
        " u'File:Bleach GC - Tasogare Ni Mamieru Shinigami Coverart.png',\n",
        " u'Podivin',\n",
        " u'Tadeusz Zielinski',\n",
        " u'Spring, Summer, Fall, Winter and... Spring',\n",
        " u'Valencas S.C.',\n",
        " u'Tor zur Dubener Heide',\n",
        " u'Zjarr e ftohte',\n",
        " u'Conversations-Lexikon mit vorzuglicher Rucksicht auf die gegenwartigen Zeiten',\n",
        " u'Grindaknivur',\n",
        " u'Paterna del Rio',\n",
        " u'Cobana Negra',\n",
        " u'Tofas S.K.',\n",
        " u'Adrian Navarro',\n",
        " u'Tidningen Aland',\n",
        " u'Beregszasz',\n",
        " u'Hermann-Bose-Gymnasium',\n",
        " u'Munsterlingen (Thurgau)',\n",
        " u'Aliancia noveho obcana',\n",
        " u'Sofuku-ji Temple',\n",
        " u'Wei Yuean-ti',\n",
        " u'Abduelmecid',\n",
        " u'Lo que le paso a Reynoso',\n",
        " u'Secretaria de la Defensa Nacional',\n",
        " u'Tasch (Valais)',\n",
        " u'Henri Joseph Eugene Gouraud',\n",
        " u'Rotheneuf',\n",
        " u'University of Florida Southwest Recreation Center',\n",
        " u'Castejon de Henares',\n",
        " u'Jacaranda-Pedra',\n",
        " u'RFC de Liege',\n",
        " u'Kiegyezes',\n",
        " u'Thomas G. McInerney',\n",
        " u'Uulbayan, Suhkbaatar',\n",
        " u'Uris Theatre',\n",
        " u'Kursunlu beaches',\n",
        " u'Goenyeli',\n",
        " u'Initiative de resistance internationaliste',\n",
        " u'Andre Lussi',\n",
        " u'Placa Francesc Macia',\n",
        " u'Southern Ui Neill',\n",
        " u'Hallands laen',\n",
        " u'Sureterm',\n",
        " u'Low country',\n",
        " u'Ioannis Papadiamantopoulos (elder)',\n",
        " u'Christian Lander',\n",
        " u'Se da Guarda',\n",
        " u'Bjarne Aagard Strom',\n",
        " u'Angelique Richaud',\n",
        " u'Legion Espanola',\n",
        " u'List of Vaesterbotten Governors',\n",
        " u'Okres Trebic',\n",
        " u'FMM Sines - Festival Musicas do Mundo',\n",
        " u'Category:Coronel Bolognesi managers',\n",
        " u'Tohmajarvi',\n",
        " u'Saint-Francois-de-Madawaska',\n",
        " u'Laspaules, Huesca',\n",
        " u'Template:Death metal',\n",
        " u'Laguna del Maule (volcano)',\n",
        " u'Cabreros del Rio, Leon',\n",
        " u'Tobias Billstroem',\n",
        " u'Solidita della nebbia',\n",
        " u'Malu Vartop',\n",
        " u'Der Fuhrer des Grossdeutschen Reichs',\n",
        " u'Jack C. Massey',\n",
        " u'Societe Nationale des Beaux-Arts',\n",
        " u'Bunscoil an tSleibhe Dhuibh',\n",
        " u'Goz-Beida',\n",
        " u'Premios MTV Latinoamerica 2006',\n",
        " u'Roma citta aperta']"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Python XML module has another way of exploring XML as well:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from xml.etree import ElementTree\n",
      "ElementTree.fromstring(data.split('\\r')[0]).find('title').text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 57,
       "text": [
        "'Martynas Gostautas'"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "titles2 = [ElementTree.fromstring(entry).find('title').text for entry in data.split('\\r')[:-1]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 27 s, sys: 0 ns, total: 27 s\n",
        "Wall time: 27 s\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that both of these are extremely slow compared to simple string parsing:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import HTMLParser\n",
      "parser = HTMLParser.HTMLParser()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "titles3 = [parser.unescape(entry.split(u'</title>')[0])\n",
      "           for entry in data.split(u'<title>')[1:]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 842 ms, sys: 427 ms, total: 1.27 s\n",
        "Wall time: 2.15 s\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titles1 == titles2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 62,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titles2 == titles3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(titles3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "100000"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titles3[::10000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 65,
       "text": [
        "[u'Martynas Gostautas',\n",
        " u'Montparnasse Bienvenue',\n",
        " u'Gyoergy Kisfaludy',\n",
        " u'Valea Rece River (Olanesti)',\n",
        " u'Adobe(r) LiveCycle Reader(r) Extensions',\n",
        " u'Eickendorf, Borde',\n",
        " u'Gustaf Weisskopf',\n",
        " u'Template:User kaj-N',\n",
        " u'Wikipedia:Articles for deletion/Asafedi',\n",
        " u'Mihaly Szekely']"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Setting up Starcluster"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run starcluster to initialise the config file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "# copy/paste this into your terminal\n",
      "starcluster\n",
      "# Select option [2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Edit the config file to reflect your AWS credentials"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```bash\n",
      "#############################################\n",
      "## AWS Credentials and Connection Settings ##\n",
      "#############################################\n",
      "[aws info]\n",
      "# This is the AWS credentials section (required).\n",
      "# These settings apply to all clusters\n",
      "# replace these with your AWS keys\n",
      "AWS_ACCESS_KEY_ID = #your_aws_access_key_id\n",
      "AWS_SECRET_ACCESS_KEY = #your_secret_access_key\n",
      "# replace this with your account number\n",
      "AWS_USER_ID= #your userid\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Add the ipcluster plugin if you haven't already.\n",
      "\n",
      "Near the bottom of `.starcluster/config:`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```bash\n",
      "######################\n",
      "## Built-in Plugins ##\n",
      "######################\n",
      "# The following plugins ship with StarCluster and should work out-of-the-box.\n",
      "# Uncomment as needed. Don't forget to update your PLUGINS list!\n",
      "# See http://star.mit.edu/cluster/docs/latest/plugins for plugin details.\n",
      "# .\n",
      "# .\n",
      "# .\n",
      "[plugin ipcluster]\n",
      "SETUP_CLASS = starcluster.plugins.ipcluster.IPCluster\n",
      "# Enable the IPython notebook server (optional)\n",
      "ENABLE_NOTEBOOK = True\n",
      "# Set a password for the notebook for increased security\n",
      "# This is optional but *highly* recommended\n",
      "NOTEBOOK_PASSWD = a-secret-password\n",
      "```"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Check EC2 Prices"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Easy Amazon EC2 Instance Comparison](http://www.ec2instances.info/)\n",
      "\n",
      "In theory, 5 r3.4xlarge spot instances at 13\u00a2/hour should work but in practice, AWS has not let me reserve any r3.4xlarge (maybe you'll have better luck).\n",
      "\n",
      "Reserving 17 r3.xlarge instances didn't work for me either (despite the fact that AWS claims the default limit on that is 20) so I am stuck using the more expensive m3.2xlarge instances:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```bash\n",
      "###########################################\n",
      "## Defining Additional Cluster Templates ##\n",
      "###########################################\n",
      "# You can also define multiple cluster templates. You can either supply all\n",
      "# configuration options as with smallcluster above, or create an\n",
      "# EXTENDS=<cluster_name> variable in the new cluster section to use all\n",
      "# settings from <cluster_name> as defaults. Below are example templates that\n",
      "# use the EXTENDS feature:\n",
      "\n",
      "[cluster mediumcluster]\n",
      "# Declares that this cluster uses smallcluster as defaults\n",
      "EXTENDS=smallcluster\n",
      "# This section is the same as smallcluster except for the following settings:\n",
      "NODE_IMAGE_ID = ami-6b211202\n",
      "NODE_INSTANCE_TYPE = m3.2xlarge\n",
      "CLUSTER_SIZE = 17\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a new authentication key for starcluster to use"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "starcluster createkey awskey -o ~/.ssh/awskey.rsa"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Successfully created keypair: awskey\n",
        ">>> fingerprint: a1:51:45:f4:87:98:d2:4d:f3:1d:4d:3f:c4:7e:98:46:cb:09:65:bf\n",
        ">>> keypair written to /home/io/.ssh/awskey.rsa\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "StarCluster - (http://star.mit.edu/cluster) (v. 0.95.5)\n",
        "Software Tools for Academics and Researchers (STAR)\n",
        "Please submit bug reports to starcluster@mit.edu\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Start your new cluster:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Will take about 3 minutes\n",
      "!starcluster start my_cluster"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "StarCluster - (http://star.mit.edu/cluster) (v. 0.95.5)\r\n",
        "Software Tools for Academics and Researchers (STAR)\r\n",
        "Please submit bug reports to starcluster@mit.edu\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Using default cluster template: smallcluster\r\n",
        ">>> Validating cluster template settings...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Cluster template settings are valid\r\n",
        ">>> Starting cluster...\r\n",
        ">>> Launching a 2-node cluster...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Creating security group @sc-my_cluster...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Reservation:r-d42473f8\r\n",
        ">>> Waiting for instances to propagate...\r\n",
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2/2 |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| 100%  \r\n",
        ">>> Waiting for cluster to come up... (updating every 30s)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Waiting for all nodes to be in a 'running' state...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r",
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2/2 |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| 100%  \r\n",
        ">>> Waiting for SSH to come up on all nodes...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1/2 |\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\                                 |  50%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1/2 ||||||||||||||||||||||||||||||||||                                 |  50%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1/2 |/////////////////////////////////                                 |  50%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2/2 |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| 100%  \r\n",
        ">>> Waiting for cluster to come up took 1.336 mins\r\n",
        ">>> The master node is ec2-54-83-85-201.compute-1.amazonaws.com\r\n",
        ">>> Configuring cluster...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Running plugin starcluster.clustersetup.DefaultClusterSetup\r\n",
        ">>> Configuring hostnames...\r\n",
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2/2 |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| 100%  \r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Creating cluster user: sgeadmin (uid: 1001, gid: 1001)\r\n",
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2/2 |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| 100%  \r\n",
        ">>> Configuring scratch space for user(s): sgeadmin\r\n",
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2/2 |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| 100%  \r\n",
        ">>> Configuring /etc/hosts on each node\r\n",
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2/2 |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| 100%  \r\n",
        ">>> Starting NFS server on master\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Configuring NFS exports path(s):\r\n",
        "/home\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Mounting all NFS export path(s) on 1 worker node(s)\r\n",
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1/1 |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| 100%  \r\n",
        ">>> Setting up NFS took 0.364 mins\r\n",
        ">>> Configuring passwordless ssh for root\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Configuring passwordless ssh for sgeadmin\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Running plugin starcluster.plugins.sge.SGEPlugin\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Configuring SGE...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Configuring NFS exports path(s):\r\n",
        "/opt/sge6\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Mounting all NFS export path(s) on 1 worker node(s)\r\n",
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1/1 |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| 100%  \r\n",
        ">>> Setting up NFS took 0.255 mins\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Installing Sun Grid Engine...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1/1 |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| 100%  \r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Creating SGE parallel environment 'orte'\r\n",
        "0/2 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2/2 |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| 100%  \r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Adding parallel environment 'orte' to queue 'all.q'\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Configuring cluster took 2.363 mins\r\n",
        ">>> Starting cluster took 3.802 mins\r\n",
        "\r\n",
        "The cluster is now ready to use. To login to the master node\r\n",
        "as root, run:\r\n",
        "\r\n",
        "    $ starcluster sshmaster my_cluster\r\n",
        "\r\n",
        "If you're having issues with the cluster you can reboot the\r\n",
        "instances and completely reconfigure the cluster from\r\n",
        "scratch using:\r\n",
        "\r\n",
        "    $ starcluster restart my_cluster\r\n",
        "\r\n",
        "When you're finished using the cluster and wish to terminate\r\n",
        "it and stop paying for service:\r\n",
        "\r\n",
        "    $ starcluster terminate my_cluster\r\n",
        "\r\n",
        "Alternatively, if the cluster uses EBS instances, you can\r\n",
        "use the 'stop' command to shutdown all nodes and put them\r\n",
        "into a 'stopped' state preserving the EBS volumes backing\r\n",
        "the nodes:\r\n",
        "\r\n",
        "    $ starcluster stop my_cluster\r\n",
        "\r\n",
        "WARNING: Any data stored in ephemeral storage (usually /mnt)\r\n",
        "will be lost!\r\n",
        "\r\n",
        "You can activate a 'stopped' cluster by passing the -x\r\n",
        "option to the 'start' command:\r\n",
        "\r\n",
        "    $ starcluster start -x my_cluster\r\n",
        "\r\n",
        "This will start all 'stopped' nodes and reconfigure the\r\n",
        "cluster.\r\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!starcluster runplugin ipcluster my_cluster"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "StarCluster - (http://star.mit.edu/cluster) (v. 0.95.5)\r\n",
        "Software Tools for Academics and Researchers (STAR)\r\n",
        "Please submit bug reports to starcluster@mit.edu\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Running plugin ipcluster\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Writing IPython cluster config files\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Starting the IPython controller and 1 engines on master\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Waiting for JSON connector file... \b \b|"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b \b/"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\b \b\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/io/.starcluster/ipcluster/SecurityGroup:@sc-my_cluster-us-east-1.json   0% || ETA:  --:--:--   0.00 B/s\r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/io/.starcluster/ipcluster/SecurityGroup:@sc-my_cluster-us-east-1.json 100% || Time: 00:00:00   1.59 K/s\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Authorizing tcp ports [44109-44109] on 0.0.0.0/0 for: control\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Authorizing tcp ports [46661-46661] on 0.0.0.0/0 for: task\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Authorizing tcp ports [47173-47173] on 0.0.0.0/0 for: notification\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Authorizing tcp ports [39491-39491] on 0.0.0.0/0 for: mux\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Authorizing tcp ports [54074-54074] on 0.0.0.0/0 for: iopub\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Authorizing tcp ports [47347-47347] on 0.0.0.0/0 for: registration\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Adding 1 engines on 1 nodes\r\n",
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0/1 |                                                                  |   0%  \r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1/1 |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||| 100%  \r\n",
        ">>> Setting up IPython web notebook for user: sgeadmin\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Creating SSL certificate for user sgeadmin\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> Authorizing tcp ports [8888-8888] on 0.0.0.0/0 for: notebook\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> IPython notebook URL: https://ec2-54-83-85-201.compute-1.amazonaws.com:8888\r\n",
        ">>> The notebook password is: guidance\r\n",
        "*** WARNING - Please check your local firewall settings if you're having\r\n",
        "*** WARNING - issues connecting to the IPython notebook\r\n",
        ">>> IPCluster has been started on SecurityGroup:@sc-my_cluster for user 'sgeadmin'\r\n",
        "with 2 engines on 2 nodes.\r\n",
        "\r\n",
        "To connect to cluster from your local machine use:\r\n",
        "\r\n",
        "from IPython.parallel import Client\r\n",
        "client = Client('/home/io/.starcluster/ipcluster/SecurityGroup:@sc-my_cluster-us-east-1.json', sshkey='/home/io/.ssh/awskey.rsa')\r\n",
        "\r\n",
        "See the IPCluster plugin doc for usage details:\r\n",
        "http://star.mit.edu/cluster/docs/latest/plugins/ipython.html\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ">>> IPCluster took 0.940 mins\r\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run the ipcluster plugin to connect your IPython notebook with the cluster"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!starcluster terminate -f my_cluster"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "StarCluster - (http://star.mit.edu/cluster) (v. 0.95.5)\r\n",
        "Software Tools for Academics and Researchers (STAR)\r\n",
        "Please submit bug reports to starcluster@mit.edu\r\n",
        "\r\n",
        "*** WARNING - Ignoring cluster settings due to --force option\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Terminate cluster my_cluster (y/n)? "
       ]
      }
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      ">>> BE SURE TO CLOSE YOUR CLUSTER <<<<"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Background"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* [Without Context, Data is Meaningless](http://dannybrown.me/2013/08/15/without-context-data-is-meaningless/)\n",
      "* [Using s3 instead of HDFS in the Cloud](http://www.technology-mania.com/2012/05/s3-instead-of-hdfs-with-hadoop_05.html)\n",
      "* [Tuple MapReduce: beyond the classic MapReduce](http://www.datasalt.com/2012/02/tuple-mapreduce-beyond-the-classic-mapreduce/)\n",
      "* [MapReduce & Hadoop API revised](http://www.datasalt.com/2012/02/mapreduce-hadoop-problems/)\n",
      "* [How Twitter Uses NoSQL\n",
      "](http://readwrite.com/2011/01/02/how-twitter-uses-nosql#awesm=~oINrJQljtJRO57)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Python Documentation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* [Parallel Magic Commands](http://ipython.org/ipython-doc/dev/parallel/magics.html)\n",
      "* [StarCluster Documentation](https://media.readthedocs.org/pdf/starcluster/latest/starcluster.pdf)\n",
      "* [STARCluster QuickStart](http://star.mit.edu/cluster/docs/latest/quickstart.html)\n",
      "* [IPython Cluster Plugin](http://star.mit.edu/cluster/docs/latest/plugins/ipython.html)\n",
      "* [A Guide to Python Frameworks for Hadoop](http://blog.cloudera.com/blog/2013/01/a-guide-to-python-frameworks-for-hadoop/)\n",
      "* [mrjob: lets you write MapReduce jobs in Python ](https://pythonhosted.org/mrjob/)\n",
      "* [Dumbo Tutorial](https://github.com/klbostee/dumbo/wiki/Short-tutorial)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}