{
 "metadata": {
  "name": "",
  "signature": "sha256:6b96c4a7376cc41d6d10ce60b06bdc0c26f0c8908d1fdbaa0abdd4d33bf6b3cf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%javascript\n",
      "function is_local(){\n",
      "  return (document.location.hostname == \"localhost\" || document.location.hostname == '127.0.0.1')\n",
      "}\n",
      "var url = is_local() ? \"http://127.0.0.1:8888/files/theme/custom.js\" : \"http://odhk.github.io/hyrule_theme/custom.js\"\n",
      "$.getScript(url)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "javascript": [
        "function is_local(){\n",
        "  return (document.location.hostname == \"localhost\" || document.location.hostname == '127.0.0.1')\n",
        "}\n",
        "var url = is_local() ? \"http://127.0.0.1:8888/files/theme/custom.js\" : \"http://odhk.github.io/hyrule_theme/custom.js\"\n",
        "$.getScript(url)"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Javascript at 0x7fc9541b5dd0>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Logistic Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> The virtue of binary is that it's the simplest possible way of representing numbers. Anything else is more complicated. You can catch errors with it, it's unambiguous in its reading, there are lots of good things about binary. So it is very, very simple once you learn how to read it.\n",
      "\n",
      "<footer>~ George M. Whitesides</footer>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![break](assets/agenda.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Logistic Regression\n",
      "1. Outcome Variables\n",
      "1. Error Terms\n",
      "1. Interpreting Results\n",
      "\n",
      "**Labs:**\n",
      "1. Logistic Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![break](assets/theory.png)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Logistic Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "|   \t|continuous\t|categorical   \t|\n",
      "|:-:\t|:-:\t|:-:\t|\n",
      "|**supervised**   \t|regression   \t|**classification**   \t|\n",
      "|**unsupervised**   \t|dimension reduction   \t|clustering   \t|"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* A generalization of the linear regression model to classification problems.\n",
      "* A discriminative classification algorithm, result does not depend completely on the data set."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In **linear regression**, we used a set of covariates to predict the value of a (continuous) outcome variable.\n",
      "In **logistic regression**, we use a set of covariates to predict probabilities of (binary) class membership. These probabilities are then mapped to class labels, thus solving the classification problem."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Probability predictions look like this."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![](assets/logistic_regression.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* ** Y ** : Probability of belonging to class\n",
      "* ** X ** : Value of independent variable"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Probabilities are \u201csnapped\u201d to class labels (eg by threshholding at 50%)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![](assets/logistic_regression_snap.png)\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that Logistic Regression is primarily used to solve a binary classification problem.\n",
      "\n",
      "Examples:\n",
      "* Was this credit transaction fraudulent? (Y/N)\n",
      "* User a boy or a girl?\n",
      "* Do I have x disease?\n",
      "* Should this stock be bought or sold?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The logistic regression model is an extension of the linear regression model, with a couple of important differences:\n",
      "    \n",
      "* Difference 1: Outcome Variables\n",
      "* Difference 2: Error Terms\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Outcome Variables"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The key variable in any regression problem is the **conditional mean** of the outcome variable y given the value of the covariate x:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ E(y|x) $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In linear regression, we assume that this conditional\n",
      "mean is a linear function taking values in (-\u221e, +\u221e):"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ E(y|x) = \\alpha + \\beta x $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Q: How is this different from just using a linear\n",
      "regression to solve a classification problem?**\n",
      "\n",
      "A: If the original values are not scaled correctly, then the\n",
      "results for data once classified 0 may be reclassified as 1.\n",
      "\n",
      "**We don\u2019t want that to happen!**\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In logistic regression, we\u2019ve seen that the conditional mean of the outcome variable takes values only in the unit interval [0, 1].\n",
      "\n",
      "0 = negative class, 1 = positive class\n",
      "\n",
      "The first step in extending the linear regression model to logistic regression is to map the outcome variable E(y|x) into the unit interval.\n",
      "\n",
      "By using a transformation called the logistic response function:\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ E(y|x) = \\pi(x) = {e^{\\alpha + \\beta x} \\over 1+e^{\\alpha + \\beta x}} = {1 \\over 1+e^{-(\\alpha + \\beta x)}} $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The curve of the natural exponentional function looks like this, with the negative exponentials resulting in a number between 0 and 1."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![](assets/exp.svg)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the logistic function, we\u2019ve already seen what this looks like:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![](assets/logistic_regression.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For any value of $x, y$ is in the interval $[0, 1]$ This is a nonlinear transformation!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The logit function is an important transformation of the logistic function. Notice that it returns the linear model!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ g(x) = \\ln\\left(\\frac{\\pi(x)}{1-\\pi(x)}\\right) = \\alpha + \\beta x $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The logit function is also called the log-odds function. This name hints at its usefulness in interpreting our results. We will see why shortly.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![break](assets/theory.png)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Error Terms"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The second difference between linear regression and the logistic regression model is in the error term.\n",
      "\n",
      "One of the key assumptions of linear regression is that the error terms follow independent Gaussian distributions with zero mean and constant variance:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ \\epsilon \\sim N(0,\\sigma^2) $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In logistic regression, the outcome variable can take only two values: 0 or 1.\n",
      "\n",
      "It\u2019s easy to show from this that instead of following a Gaussian distribution, the error term in logistic regression follows a Bernoulli distribution:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ \\epsilon \\sim B(0,\\pi(1 - \\pi))) $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is the same distribution followed by a coin toss. Think about why this makes sense!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Bernoulli Distribution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Bernoulli distribution is a discrete distribution having two possible outcomes labelled by $n=0$ and $n=1$ in which $n=1$ (\"success\") occurs with probability $p$ and $n=0$ (\"failure\") occurs with probability $q=1-p$, where $0<p<1$. It therefore has probability density function"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ f(k;p) = \\begin{cases}\n",
      "    p & \\text{if } k=1 \\\\\\\\ \n",
      "    1-p & \\text{if } k=0\n",
      "\\end{cases}$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "import scipy.stats\n",
      "from scipy.stats import bernoulli"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bernoulli.rvs(0.6, size=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "array([0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
        "       0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
        "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
        "       0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
        "       1, 1, 1, 1, 1, 0, 1, 1])"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = np.arange(2)\n",
      "\n",
      "colors = matplotlib.rcParams['axes.color_cycle']\n",
      "plt.figure(figsize=(16,8))\n",
      "for i, p in enumerate([0.1, 0.2, 0.6, 0.7]):\n",
      "    ax = plt.subplot(1, 4, i+1)\n",
      "    plt.bar(a, bernoulli.pmf(a, p), label=p, color=colors[i], alpha=0.5)\n",
      "    ax.xaxis.set_ticks(a)\n",
      "\n",
      "    plt.legend(loc=0)\n",
      "    if i == 0:\n",
      "        plt.ylabel(\"PDF at $k$\")\n",
      "    \n",
      "\n",
      "plt.suptitle(\"Bernoulli probability\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x32bd750>"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "An Aside : GLM"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These two key differences define the logistic regression model, and they also lead us to a kind of unification of regression techniques called **generalized linear models**.\n",
      "\n",
      "Briefly, GLMs generalize the distribution of the error term, and allow the conditional mean of the response variable to be related to the linear model by a link function.\n",
      "\n",
      "In the present case, the error term follows a Bernoulli distribution, and the logit is the link function that connects us to the linear predictor."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ g(x) = \\ln\\left(\\frac{\\pi(x)}{1-\\pi(x)}\\right) = \\alpha + \\beta x $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since the Bernoulli distribution and the logit function share a common parameter \u03c0, we say that the logit is the canonical link function for the Bernoulli distribution."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![break](assets/theory.png)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Interpreting Results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In linear regression, the parameter \u03b2 represents the change in the response variable for a unit change in the\n",
      "covariate. \n",
      "\n",
      "In logistic regression, \u03b2 represents the change in the logit function for a unit change in the covariate.\n",
      "\n",
      "Interpreting this change in the logit function requires another definition first."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Your independent variables $X_i$ can be continuous or binary. The regression coefficients $b_i$ can be exponentiated to give you the change in odds of $Y$ per change in $X_i$, i.e.,"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In English, you can say that the odds of $Y=1$ increase by a factor of $e^{b_i}$ per unit change in $X$i."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The odds of an event are given by the ratio of the probability of the event by its complement:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ O(x=1) = \\frac{\\pi(1)}{(1-\\pi(1))}$$ "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The odds ratio of a binary event is given by the odds of the event divided by the odds of its complement:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$ O R={O(x=1) \\over O(x=0)}={ \\pi(1)/[1-\\pi(1)] \\over \\pi(0)/[1-\\pi(0)] }$$ "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Substituting the definition of $\u03c0(x)$ into this equation yields (after some algebra),\n",
      "\n",
      "$$ O R = e^\u03b2 $$\n",
      "\n",
      "This simple relationship between the odds ratio and the parameter $\u03b2$ is what makes logistic regression such a powerful tool."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Q: So how do we interpret this?**\n",
      "\n",
      "A: The odds ratio of a binary event gives the increase in likelihood of an outcome if the event occurs."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Suppose we are interested in mobile purchase behavior. Let $y$ be a class label denoting purchase/no purchase, and let $x$ denote a mobile OS (for example, Android).\n",
      "\n",
      "In this case, an odds ratio of $2$ (eg, $\u03b2 = log(2)$) indicates that a purchase is twice as likely for an Android user as for a non-Android user."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![break](assets/code.png)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Logistic Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Work through the Logistic Regression model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Set some Pandas options\n",
      "pd.set_option('max_columns', 30)\n",
      "pd.set_option('max_rows', 20)\n",
      "\n",
      "# Store data in a consistent place\n",
      "DATA_DIR = '../data/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's see if we can use logistic regression to predict what kinds of beer people like."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl http://www-958.ibm.com/software/analytics/manyeyes/datasets/af-er-beer-dataset/versions/1.txt > ../data/beer.tsv    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
        "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 20 19771   20  4104    0     0   2551      0  0:00:07  0:00:01  0:00:06  2550"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 19771  100 19771    0     0  10139      0  0:00:01  0:00:01 --:--:-- 10138\r\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "beer = pd.read_csv(DATA_DIR + 'beer.tsv', delimiter=\"\\t\")\n",
      "beer.head(50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Rank</th>\n",
        "      <th>Name</th>\n",
        "      <th>Brewery</th>\n",
        "      <th>Type</th>\n",
        "      <th>ABV</th>\n",
        "      <th>WR</th>\n",
        "      <th>Reviews</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td>  1</td>\n",
        "      <td>                                 Heady Topper</td>\n",
        "      <td>                                     The Alchemist</td>\n",
        "      <td>      Imperial IPA</td>\n",
        "      <td>  8.0</td>\n",
        "      <td> 4.69</td>\n",
        "      <td> 3146</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td>  2</td>\n",
        "      <td>                            Pliny The Younger</td>\n",
        "      <td>                     Russian River Brewing Company</td>\n",
        "      <td>      Imperial IPA</td>\n",
        "      <td> 11.0</td>\n",
        "      <td> 4.65</td>\n",
        "      <td> 1572</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td>  3</td>\n",
        "      <td>                              Pliny The Elder</td>\n",
        "      <td>                     Russian River Brewing Company</td>\n",
        "      <td>      Imperial IPA</td>\n",
        "      <td>  8.0</td>\n",
        "      <td> 4.64</td>\n",
        "      <td> 6129</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td>  4</td>\n",
        "      <td>                  Founders CBS Imperial Stout</td>\n",
        "      <td>                          Founders Brewing Company</td>\n",
        "      <td>    Imperial Stout</td>\n",
        "      <td> 10.6</td>\n",
        "      <td> 4.63</td>\n",
        "      <td> 2026</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td>  5</td>\n",
        "      <td>      Founders KBS (Kentucky Breakfast Stout)</td>\n",
        "      <td>                          Founders Brewing Company</td>\n",
        "      <td>    Imperial Stout</td>\n",
        "      <td> 11.2</td>\n",
        "      <td> 4.61</td>\n",
        "      <td> 4714</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td>  6</td>\n",
        "      <td>                                  Zombie Dust</td>\n",
        "      <td>                Three Floyds Brewing Co. &amp; Brewpub</td>\n",
        "      <td> American Pale Ale</td>\n",
        "      <td>  6.4</td>\n",
        "      <td> 4.61</td>\n",
        "      <td> 2978</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td>  7</td>\n",
        "      <td>               Trappist Westvleteren 12 (XII)</td>\n",
        "      <td> Brouwerij Westvleteren (Sint-Sixtusabdij van W...</td>\n",
        "      <td>               NaN</td>\n",
        "      <td> 10.2</td>\n",
        "      <td> 4.61</td>\n",
        "      <td> 2891</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td>  8</td>\n",
        "      <td>            Bourbon County Brand Coffee Stout</td>\n",
        "      <td>                             Goose Island Beer Co.</td>\n",
        "      <td>    Imperial Stout</td>\n",
        "      <td> 14.0</td>\n",
        "      <td> 4.61</td>\n",
        "      <td> 2014</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td>  9</td>\n",
        "      <td>                                     Parabola</td>\n",
        "      <td>                      Firestone Walker Brewing Co.</td>\n",
        "      <td>    Imperial Stout</td>\n",
        "      <td> 12.5</td>\n",
        "      <td> 4.55</td>\n",
        "      <td> 2178</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 10</td>\n",
        "      <td>   Bourbon Barrel Aged Vanilla Bean Dark Lord</td>\n",
        "      <td>                Three Floyds Brewing Co. &amp; Brewpub</td>\n",
        "      <td>    Imperial Stout</td>\n",
        "      <td> 15.0</td>\n",
        "      <td> 4.55</td>\n",
        "      <td>  429</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 11</td>\n",
        "      <td>                                    The Abyss</td>\n",
        "      <td>                                  Deschute Brewery</td>\n",
        "      <td>    Imperial Stout</td>\n",
        "      <td> 11.0</td>\n",
        "      <td> 4.53</td>\n",
        "      <td> 3032</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 12</td>\n",
        "      <td>                                 Supplication</td>\n",
        "      <td>                     Russian River Brewing Company</td>\n",
        "      <td>    Imperial Stout</td>\n",
        "      <td>  7.0</td>\n",
        "      <td> 4.53</td>\n",
        "      <td> 2715</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> 13</td>\n",
        "      <td>                           Bell's Hopslam Ale</td>\n",
        "      <td>                            Bell's Brewing Company</td>\n",
        "      <td>      Imperial IPA</td>\n",
        "      <td> 10.0</td>\n",
        "      <td> 4.52</td>\n",
        "      <td> 6267</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> 14</td>\n",
        "      <td>                         Cantillon Fou' Foune</td>\n",
        "      <td>                               Brasserie Cantillon</td>\n",
        "      <td>             Fruit</td>\n",
        "      <td>  5.0</td>\n",
        "      <td> 4.52</td>\n",
        "      <td>  914</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td> 15</td>\n",
        "      <td>                     Founders Breakfast Stout</td>\n",
        "      <td>                          Founders Brewing Company</td>\n",
        "      <td>    Imperial Stout</td>\n",
        "      <td>  8.3</td>\n",
        "      <td> 4.51</td>\n",
        "      <td> 6956</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td> 16</td>\n",
        "      <td>                      Trappistes Rochefort 10</td>\n",
        "      <td>                            Brasserie de Rochefort</td>\n",
        "      <td>               NaN</td>\n",
        "      <td> 11.3</td>\n",
        "      <td> 4.51</td>\n",
        "      <td> 4451</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> 17</td>\n",
        "      <td>                   Bourbon County Brand Stout</td>\n",
        "      <td>                             Goose Island Beer Co.</td>\n",
        "      <td>    Imperial Stout</td>\n",
        "      <td> 15.0</td>\n",
        "      <td> 4.51</td>\n",
        "      <td> 4239</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> 18</td>\n",
        "      <td>                                   Citra DIPA</td>\n",
        "      <td>                        Kern River Brewing Company</td>\n",
        "      <td>      Imperial IPA</td>\n",
        "      <td>  8.0</td>\n",
        "      <td> 4.51</td>\n",
        "      <td>  714</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td> 19</td>\n",
        "      <td>                     Hunahpu's Imperial Stout</td>\n",
        "      <td>                                Cigar City Brewing</td>\n",
        "      <td>    Imperial Stout</td>\n",
        "      <td> 11.0</td>\n",
        "      <td> 4.50</td>\n",
        "      <td> 1204</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td> 20</td>\n",
        "      <td> Dark Horse Bourbon Barrel Aged Plead The 5th</td>\n",
        "      <td>                        Dark Horse Brewing Company</td>\n",
        "      <td>    Imperial Stout</td>\n",
        "      <td> 14.0</td>\n",
        "      <td> 4.50</td>\n",
        "      <td>  787</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th></th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>50 rows \u00d7 7 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "    Rank                                          Name  \\\n",
        "0      1                                  Heady Topper   \n",
        "1      2                             Pliny The Younger   \n",
        "2      3                               Pliny The Elder   \n",
        "3      4                   Founders CBS Imperial Stout   \n",
        "4      5       Founders KBS (Kentucky Breakfast Stout)   \n",
        "5      6                                   Zombie Dust   \n",
        "6      7                Trappist Westvleteren 12 (XII)   \n",
        "7      8             Bourbon County Brand Coffee Stout   \n",
        "8      9                                      Parabola   \n",
        "9     10    Bourbon Barrel Aged Vanilla Bean Dark Lord   \n",
        "10    11                                     The Abyss   \n",
        "11    12                                  Supplication   \n",
        "12    13                            Bell's Hopslam Ale   \n",
        "13    14                          Cantillon Fou' Foune   \n",
        "14    15                      Founders Breakfast Stout   \n",
        "15    16                       Trappistes Rochefort 10   \n",
        "16    17                    Bourbon County Brand Stout   \n",
        "17    18                                    Citra DIPA   \n",
        "18    19                      Hunahpu's Imperial Stout   \n",
        "19    20  Dark Horse Bourbon Barrel Aged Plead The 5th   \n",
        "     ...                                           ...   \n",
        "\n",
        "                                              Brewery               Type  \\\n",
        "0                                       The Alchemist       Imperial IPA   \n",
        "1                       Russian River Brewing Company       Imperial IPA   \n",
        "2                       Russian River Brewing Company       Imperial IPA   \n",
        "3                            Founders Brewing Company     Imperial Stout   \n",
        "4                            Founders Brewing Company     Imperial Stout   \n",
        "5                  Three Floyds Brewing Co. & Brewpub  American Pale Ale   \n",
        "6   Brouwerij Westvleteren (Sint-Sixtusabdij van W...                NaN   \n",
        "7                               Goose Island Beer Co.     Imperial Stout   \n",
        "8                        Firestone Walker Brewing Co.     Imperial Stout   \n",
        "9                  Three Floyds Brewing Co. & Brewpub     Imperial Stout   \n",
        "10                                   Deschute Brewery     Imperial Stout   \n",
        "11                      Russian River Brewing Company     Imperial Stout   \n",
        "12                             Bell's Brewing Company       Imperial IPA   \n",
        "13                                Brasserie Cantillon              Fruit   \n",
        "14                           Founders Brewing Company     Imperial Stout   \n",
        "15                             Brasserie de Rochefort                NaN   \n",
        "16                              Goose Island Beer Co.     Imperial Stout   \n",
        "17                         Kern River Brewing Company       Imperial IPA   \n",
        "18                                 Cigar City Brewing     Imperial Stout   \n",
        "19                         Dark Horse Brewing Company     Imperial Stout   \n",
        "                                                  ...                ...   \n",
        "\n",
        "     ABV    WR  Reviews  \n",
        "0    8.0  4.69     3146  \n",
        "1   11.0  4.65     1572  \n",
        "2    8.0  4.64     6129  \n",
        "3   10.6  4.63     2026  \n",
        "4   11.2  4.61     4714  \n",
        "5    6.4  4.61     2978  \n",
        "6   10.2  4.61     2891  \n",
        "7   14.0  4.61     2014  \n",
        "8   12.5  4.55     2178  \n",
        "9   15.0  4.55      429  \n",
        "10  11.0  4.53     3032  \n",
        "11   7.0  4.53     2715  \n",
        "12  10.0  4.52     6267  \n",
        "13   5.0  4.52      914  \n",
        "14   8.3  4.51     6956  \n",
        "15  11.3  4.51     4451  \n",
        "16  15.0  4.51     4239  \n",
        "17   8.0  4.51      714  \n",
        "18  11.0  4.50     1204  \n",
        "19  14.0  4.50      787  \n",
        "     ...   ...      ...  \n",
        "\n",
        "[50 rows x 7 columns]"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "set(beer['Type'])\n",
      "# beer['Type'].unique"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "{'American Amber',\n",
        " 'American Barleywine',\n",
        " 'American Black Ale',\n",
        " 'American Double',\n",
        " 'American IPA',\n",
        " 'American Pale Ale',\n",
        " 'American Pale Lager',\n",
        " 'American Pale Wheat Ale',\n",
        " 'American Porter',\n",
        " 'American Stout',\n",
        " 'American Strong Ale',\n",
        " 'American Wild Ale',\n",
        " 'Belgian IPA',\n",
        " 'Belgian Pale Ale',\n",
        " 'Belgian Strong Dark Ale',\n",
        " 'Belgian Strong Pale Ale',\n",
        " 'Blatic Porter',\n",
        " 'Doppelbock',\n",
        " 'Dunkelweizen',\n",
        " 'Eisbock',\n",
        " 'English Barleywine',\n",
        " 'Farmhouse Ale',\n",
        " 'Flanders Oud Bruin',\n",
        " 'Flanders Red Ale',\n",
        " 'Fruit',\n",
        " 'Gueuze',\n",
        " 'Hefeweizen',\n",
        " 'Imperial IPA',\n",
        " 'Imperial Pilsner',\n",
        " 'Imperial Stout',\n",
        " 'Lambic',\n",
        " 'Lambic Gueuze',\n",
        " 'Oatmeal Stout',\n",
        " 'Old Ale',\n",
        " 'Porter',\n",
        " 'Red Ale',\n",
        " 'Russian Imperial Stout',\n",
        " 'Rye Beer',\n",
        " 'Scoth Ale',\n",
        " 'Tripel',\n",
        " 'Vegetable Beer',\n",
        " 'Weizenbock',\n",
        " 'Wild Ale'}"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beer.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Rank</th>\n",
        "      <th>ABV</th>\n",
        "      <th>WR</th>\n",
        "      <th>Reviews</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 250.000000</td>\n",
        "      <td> 248.000000</td>\n",
        "      <td> 250.000000</td>\n",
        "      <td>  250.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td> 125.500000</td>\n",
        "      <td>   9.177823</td>\n",
        "      <td>   4.313600</td>\n",
        "      <td> 1504.832000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>  72.312977</td>\n",
        "      <td>   3.178589</td>\n",
        "      <td>   0.105228</td>\n",
        "      <td> 1440.856384</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   4.000000</td>\n",
        "      <td>   4.200000</td>\n",
        "      <td>  107.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>  63.250000</td>\n",
        "      <td>   7.000000</td>\n",
        "      <td>   4.230000</td>\n",
        "      <td>  447.750000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td> 125.500000</td>\n",
        "      <td>   9.000000</td>\n",
        "      <td>   4.280000</td>\n",
        "      <td>  935.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td> 187.750000</td>\n",
        "      <td>  10.500000</td>\n",
        "      <td>   4.360000</td>\n",
        "      <td> 2162.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td> 250.000000</td>\n",
        "      <td>  29.000000</td>\n",
        "      <td>   4.690000</td>\n",
        "      <td> 7320.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>8 rows \u00d7 4 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "             Rank         ABV          WR      Reviews\n",
        "count  250.000000  248.000000  250.000000   250.000000\n",
        "mean   125.500000    9.177823    4.313600  1504.832000\n",
        "std     72.312977    3.178589    0.105228  1440.856384\n",
        "min      1.000000    4.000000    4.200000   107.000000\n",
        "25%     63.250000    7.000000    4.230000   447.750000\n",
        "50%    125.500000    9.000000    4.280000   935.000000\n",
        "75%    187.750000   10.500000    4.360000  2162.000000\n",
        "max    250.000000   29.000000    4.690000  7320.000000\n",
        "\n",
        "[8 rows x 4 columns]"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beer = beer.dropna()\n",
      "def good(x):\n",
      "    if x > 4.3:\n",
      "        return 1\n",
      "    else:\n",
      "        return 0\n",
      "\n",
      "beer['Good'] = beer['WR'].apply(good)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's see how fit goes using just Reviews and ABV."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import linear_model\n",
      "\n",
      "logm = linear_model.LogisticRegression()\n",
      "\n",
      "X = beer[ ['Reviews', 'ABV'] ].values\n",
      "y = beer['Good'].values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logm.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logm.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "array([0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0])"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logm.score(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "0.62393162393162394"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We end up with a value around .62, which is only slightly higher than random (random = .5, like a coin flip).\n",
      "\n",
      "Question: What data can we use in this data frame to determine what kind of beer it is? This may be a better indicator! Note, we can use regex's to create a new column."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![break](assets/voronoi.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Write a function that groups our beers together using regex (example here):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "# If this is true, then there was a match!\n",
      "re.search('Apple', 'Apple Computer') != None\n",
      "\n",
      "# or you can use the str.contains method\n",
      "beer['Name'].str.contains('Pliny')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "0    False\n",
        "1     True\n",
        "2     True\n",
        "3    False\n",
        "4    False\n",
        "5    False\n",
        "7    False\n",
        "8    False\n",
        "...\n",
        "242    False\n",
        "243    False\n",
        "244    False\n",
        "245    False\n",
        "246    False\n",
        "247    False\n",
        "248    False\n",
        "249    False\n",
        "Name: Name, Length: 234, dtype: bool"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll be grouping our beers into **Ale**, **Stout**, **IPA**, and **Lager**. \n",
      "\n",
      "Of course, due to how we handle our data (numpy arrays), these have to be vectorized into four separate columns. \n",
      "\n",
      "Finally, we can create a logistic regression model using these four to predict if \"Good\" = 0 or 1."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = beer[ ['Ale', 'Stout', 'IPA', 'Lager'] ].values\n",
      "y = beer['Good'].values\n",
      "\n",
      "logm.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And consider looking again at the `coef_`, `intercept_`, etc. We can consider precision based on `|predicted - actual|` as well as looking at `.score()`.\n",
      "\n",
      "Consider using `set_params(penalty = 'l1')` to see how your results change, and if this has become more precise or not. How does this align with what we discussed with `l1` and `l2` norm in lecture?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![break](assets/voronoi.png)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Homework"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Spend some time this week to predict the 2012 salary per player using the 2011 data in the data set below:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> http://cl.ly/RUED (note curl won't work here)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You'll need to \"munge\" through the data by plotting various data against Salary to understand the relationship for each value in order to interpret the best model. I'd focus around these to start with:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[ [\"HR\", \"RBI\", 'R', \"G\", \"SB\", \"salary\", 'height', 'weight', 'yearID'] ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "[['HR', 'RBI', 'R', 'G', 'SB', 'salary', 'height', 'weight', 'yearID']]"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "but jump around and look at the variety of data available (and use feature selection!) to determine how significant the data available is in predicting salary.\n",
      "\n",
      "Keep in mind that you cannot have a NEGATIVE salary, so if you have a negative prediction, whoops. :)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![break](assets/resources.png)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Resources"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* [Regression Analysis by Example](http://type.hk:2551/calibre/browse/book/294) (**Chapter 12**) - Samprit Chatterjee"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Articles"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* [The Bernoulli distribution mean and variance](http://hawaiireedlab.com/wpress/?p=1019)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Code"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* [Overview with plots of statistical distributions](http://nbviewer.ipython.org/urls/gist.github.com/mattions/6113437/raw/c5468ea930d6960225d83e112d7f3d00d9c13398/Exploring+different+distribution.ipynb)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}